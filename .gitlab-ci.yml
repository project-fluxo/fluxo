# =================================================================================================================================
# Stages to be executed, each stage is a collection of jobs pointing to the stage
# =================================================================================================================================

stages:
  - build
  - short_runs
  - cleanup

variables:
  GIT_STRATEGY: none
  GLOBAL_CACHE_PATH: "/home/gitlab-runner/globalcache/${CI_PIPELINE_ID}_${CI_COMMIT_REF_NAME}"
  SSH_GITLAB: "git@gitlab.com:${CI_PROJECT_PATH}.git"

# =================================================================================================================================
# yaml variables
# hidden key that defines an anchor named 'job_def_build_intel'
# =================================================================================================================================

.job_template: &job_def_build_intel
  stage: build 
  tags:
    - vm_linux
  before_script:
    - pwd
    - echo ${SSH_GITLAB} ${GLOBAL_CACHE_PATH} ${NIGHTLY_RUNNER}
    - if [ ! -f .gitlab-ci.yml ] ; then  # git repo does not exist 
    - cd .. ; rm -rf ${CI_PROJECT_NAME} ; git clone ${SSH_GITLAB} ${CI_PROJECT_NAME} ; fi # use ssh
    - cd ${CI_PROJECT_DIR}
    - git remote set-url origin ${SSH_GITLAB}
    - git fetch origin
    - git stash; git stash clear       # be sure that its clean before checkout and pull
    - git checkout ${CI_COMMIT_REF_NAME} ; git pull origin ${CI_COMMIT_REF_NAME} 
    - mkdir -p ${GLOBAL_CACHE_PATH}  
    - . ~/environments/modules_for_fluxo_intel ; pwd

#--------------------------------------------------------------------------------------------------------------------------------
.job_template: &job_def_short_runs_intel
  stage: short_runs 
  tags:
    - vm_linux
  before_script:
    - . ~/environments/modules_for_fluxo_intel ; pwd

#--------------------------------------------------------------------------------------------------------------------------------
.job_template: &job_def_cleanup
  stage: cleanup 
  tags:
    - vm_linux

# =================================================================================================================================
# Stage "build"
# artifacts: name: "${CI_PIPELINE_ID}_${CI_JOB_NAME}_${CI_COMMIT_REF_NAME}"
#
# SHORT SYNTAX EXPLANATIONS FOR THE JOB, FOR DETAILS VISIT:    ===> https://docs.gitlab.com/ce/ci/yaml/   <===
# "stage:"         makes the job part of a stage defined above
# "tags:"          selects the runner
# "only:"          restricts the execution of the job to a git branch or tag
# "before_script:" shell commands to be executed before the main script. 
# "script:"        shell commands for the test. If a shell command exits with >0, the job is marked as "failed", else as "passed".
#                  commands after a failing one are not executed anymore!
# "after_script:"  shell commands after passed OR failed script. Careful, the current directory is always the root of the repo!
# "artifacts:"     keep data from the job which is uploaded to gitlab.com. You really should set a duration to expiration.
#                  "when:" can be either on_failure, on_success or always
# =================================================================================================================================

build_mhd:
  <<: *job_def_build_intel
  script: 
    - cd tests; pwd; echo ${NIGHTLY_RUNNER}
    - rm -rf dirx_3* log_3*
    - if [ -n "${NIGHTLY_RUNNER}" ]; then python build_tests.py -p 2 -stage 0 -buildhdf5 0 -case 300-399 
    - else python build_tests.py -p 2 -stage 0 -buildhdf5 0 -case 301,304 ;  fi
    - ls -l; mv dirx_3* ${GLOBAL_CACHE_PATH}/.
  after_script:
    - pwd 
  artifacts:
    name: "${CI_PIPELINE_ID}_${CI_COMMIT_REF_NAME}_${CI_JOB_NAME}"
    expire_in: 1 hour
    when: on_failure
    paths:
    - tests/log_3*.txt

#--------------------------------------------------------------------------------------------------------------------------------
#build_linadv:
#  <<: *job_def_build_intel # Merge the contents of the 'job_def_build_intel' alias
#  script: 
#    - cd tests; pwd; echo ${NIGHTLY_RUNNER}
#    - rm -rf dirx_1* log_1*.txt
#    - if [ -n "${NIGHTLY_RUNNER}" ]; then python build_tests.py -p 2 -stage 0 -buildhdf5 0 -case 100-199
#    - else python build_tests.py -p 2 -stage 0 -buildhdf5 0 -case 101,103 ;  fi
#    - ls ; mv dirx_1* ${GLOBAL_CACHE_PATH}/.
#  after_script:
#    - pwd 
#  artifacts:
#    name: "${CI_PIPELINE_ID}_${CI_COMMIT_REF_NAME}_${CI_JOB_NAME}"
#    expire_in: 1 hour
#    when: on_failure
#    paths:
#    - tests/log_1*.txt

#--------------------------------------------------------------------------------------------------------------------------------
build_maxwell:
  <<: *job_def_build_intel
  script: 
    - cd tests; pwd; echo ${NIGHTLY_RUNNER}
    - rm -rf dirx_2* log_2*
    - if [ -n "${NIGHTLY_RUNNER}" ]; then python build_tests.py -p 2 -stage 0 -buildhdf5 0 -case 200-299 
    - else python build_tests.py -p 2 -stage 0 -buildhdf5 0 -case 201 ;  fi
    - ls ; mv dirx_2* ${GLOBAL_CACHE_PATH}/.
  after_script:
    - pwd 
  artifacts:
    name: "${CI_PIPELINE_ID}_${CI_COMMIT_REF_NAME}_${CI_JOB_NAME}"
    expire_in: 1 hour
    when: on_failure
    paths:
    - tests/log_2*.txt


#--------------------------------------------------------------------------------------------------------------------------------
build_nav-st:
  <<: *job_def_build_intel
  script: 
    - cd tests; pwd; echo ${NIGHTLY_RUNNER}
    - rm -rf dirx_4* log_4*
    - if [ -n "${NIGHTLY_RUNNER}" ]; then python build_tests.py -p 2 -stage 0 -buildhdf5 0 -case 400-499 
    - else python build_tests.py -p 2 -stage 0 -buildhdf5 0 -case 401,403 ;  fi
    - ls ; mv dirx_4* ${GLOBAL_CACHE_PATH}/.
  after_script:
    - pwd 
  artifacts:
    name: "${CI_PIPELINE_ID}_${CI_COMMIT_REF_NAME}_${CI_JOB_NAME}"
    expire_in: 1 hour
    when: on_failure
    paths:
    - tests/log_4*.txt

# =================================================================================================================================
# Stage "short_runs"
# =================================================================================================================================
short_runs_mhd:
  <<: *job_def_short_runs_intel
  script: 
    - cd tests; pwd
    - rm -f freestream/log_3*.txt
    - rm -rf dirx_3*; mv ${GLOBAL_CACHE_PATH}/dirx_3* . 
    - if [ -n "${NIGHTLY_RUNNER}" ]; then python build_tests.py -p 2 -stage 2 -case 300-399 
    - else python build_tests.py -p 2 -stage 2 -case 301,304 ;  fi
  after_script:
    - pwd 
  artifacts:
    name: "${CI_PIPELINE_ID}_${CI_COMMIT_REF_NAME}_${CI_JOB_NAME}"
    expire_in: 1 hour
    when: on_failure
    paths:
    - tests/freestream/log_3*.txt

#--------------------------------------------------------------------------------------------------------------------------------

#short_runs_linadv:
#  <<: *job_def_short_runs_intel
#  script: 
#    - cd tests; pwd
#    - rm -f freestream/log_1*.txt
#    - rm -rf dirx_1* ; mv ${GLOBAL_CACHE_PATH}/dirx_1* . 
#    - if [ -n "${NIGHTLY_RUNNER}" ]; then python build_tests.py -p 2 -stage 2 -case 100-199 
#    - else python build_tests.py -p 2 -stage 2 -case 101,103 ;  fi
#  after_script:
#    - pwd 
#  artifacts:
#    name: "${CI_PIPELINE_ID}_${CI_COMMIT_REF_NAME}_${CI_JOB_NAME}"
#    expire_in: 1 hour
#    when: on_failure
#    paths:
#    - tests/freestream/log_1*.txt

#--------------------------------------------------------------------------------------------------------------------------------
short_runs_nav-st:
  <<: *job_def_short_runs_intel
  script: 
    - cd tests; pwd
    - rm -f freestream/log_4*.txt
    - rm -rf dirx_4* ; mv ${GLOBAL_CACHE_PATH}/dirx_4* . 
    - if [ -n "${NIGHTLY_RUNNER}" ]; then python build_tests.py -p 2 -stage 2 -case 400-499 
    - else python build_tests.py -p 2 -stage 2 -case 401,403 ;  fi
  after_script:
    - pwd 
  artifacts:
    name: "${CI_PIPELINE_ID}_${CI_COMMIT_REF_NAME}_${CI_JOB_NAME}"
    expire_in: 1 hour
    when: on_failure
    paths:
    - tests/freestream/log_4*.txt

# =================================================================================================================================
# Stage "cleanup"
# =================================================================================================================================
cleanup_cache:
  <<: *job_def_cleanup
  when: always
  script:
    - pwd
    - echo "remove:" ${GLOBAL_CACHE_PATH}
    - rm -rf ${GLOBAL_CACHE_PATH}
